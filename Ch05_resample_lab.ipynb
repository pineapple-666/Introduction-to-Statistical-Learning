{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "dc2d635a",
      "metadata": {
        "id": "dc2d635a"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6dde3cef",
      "metadata": {
        "id": "6dde3cef"
      },
      "source": [
        "# Cross-Validation and the Bootstrap\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/intro-stat-learning/ISLP_labs/blob/v2.2/Ch05-resample-lab.ipynb\">\n",
        "<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/intro-stat-learning/ISLP_labs/v2.2?labpath=Ch05-resample-lab.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9fd4324",
      "metadata": {
        "id": "a9fd4324"
      },
      "source": [
        "In this lab, we explore the resampling techniques covered in this\n",
        "chapter. Some of the commands in this lab may take a while to run on\n",
        "your computer.\n",
        "\n",
        "We again begin by placing most of our imports at this top level."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f1deb5cc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:13.493284Z",
          "iopub.status.busy": "2024-06-04T23:19:13.492950Z",
          "iopub.status.idle": "2024-06-04T23:19:14.143174Z",
          "shell.execute_reply": "2024-06-04T23:19:14.142882Z"
        },
        "lines_to_next_cell": 2,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1deb5cc",
        "outputId": "cd701fc8-7dd0-4335-e10c-0e2f02a70654"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ISLP in /usr/local/lib/python3.12/dist-packages (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.12/dist-packages (from ISLP) (2.0.2)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.12/dist-packages (from ISLP) (1.16.2)\n",
            "Requirement already satisfied: pandas>=0.20 in /usr/local/lib/python3.12/dist-packages (from ISLP) (2.2.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from ISLP) (5.4.0)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.12/dist-packages (from ISLP) (1.6.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from ISLP) (1.5.2)\n",
            "Requirement already satisfied: statsmodels>=0.13 in /usr/local/lib/python3.12/dist-packages (from ISLP) (0.14.5)\n",
            "Requirement already satisfied: lifelines in /usr/local/lib/python3.12/dist-packages (from ISLP) (0.30.0)\n",
            "Requirement already satisfied: pygam in /usr/local/lib/python3.12/dist-packages (from ISLP) (0.10.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from ISLP) (2.8.0+cu126)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.12/dist-packages (from ISLP) (2.5.5)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.12/dist-packages (from ISLP) (1.8.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.20->ISLP) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.20->ISLP) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.20->ISLP) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->ISLP) (3.6.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.13->ISLP) (1.0.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.13->ISLP) (25.0)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.12/dist-packages (from lifelines->ISLP) (3.10.0)\n",
            "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.12/dist-packages (from lifelines->ISLP) (1.8.0)\n",
            "Requirement already satisfied: autograd-gamma>=0.3 in /usr/local/lib/python3.12/dist-packages (from lifelines->ISLP) (0.5.0)\n",
            "Requirement already satisfied: formulaic>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from lifelines->ISLP) (1.2.1)\n",
            "Requirement already satisfied: progressbar2<5,>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from pygam->ISLP) (4.5.0)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning->ISLP) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>5.4 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning->ISLP) (6.0.3)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>4.5.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning->ISLP) (4.15.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning->ISLP) (0.15.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (3.4.0)\n",
            "Requirement already satisfied: interface-meta>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from formulaic>=0.2.2->lifelines->ISLP) (1.3.0)\n",
            "Requirement already satisfied: narwhals>=1.17 in /usr/local/lib/python3.12/dist-packages (from formulaic>=0.2.2->lifelines->ISLP) (2.9.0)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.12/dist-packages (from formulaic>=0.2.2->lifelines->ISLP) (2.0.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (3.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (3.2.5)\n",
            "Requirement already satisfied: python-utils>=3.8.1 in /usr/local/lib/python3.12/dist-packages (from progressbar2<5,>=4.2.0->pygam->ISLP) (3.9.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=0.20->ISLP) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->ISLP) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->ISLP) (3.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (3.11)\n"
          ]
        }
      ],
      "source": [
        "!pip install ISLP\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from ISLP import load_data\n",
        "from ISLP.models import (ModelSpec as MS,\n",
        "                         summarize,\n",
        "                         poly)\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afa08b62",
      "metadata": {
        "id": "afa08b62"
      },
      "source": [
        "There are several new imports needed for this lab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "268c41b3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:14.144884Z",
          "iopub.status.busy": "2024-06-04T23:19:14.144773Z",
          "iopub.status.idle": "2024-06-04T23:19:14.146541Z",
          "shell.execute_reply": "2024-06-04T23:19:14.146330Z"
        },
        "lines_to_next_cell": 2,
        "id": "268c41b3"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "from sklearn.model_selection import \\\n",
        "     (cross_validate,\n",
        "      KFold,\n",
        "      ShuffleSplit)\n",
        "from sklearn.base import clone\n",
        "from ISLP.models import sklearn_sm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c04f8e4",
      "metadata": {
        "id": "1c04f8e4"
      },
      "source": [
        "## The Validation Set Approach\n",
        "We explore the use of the validation set approach in order to estimate\n",
        "the test error rates that result from fitting various linear models on\n",
        "the  `Auto`  data set. https://islp.readthedocs.io/en/latest/datasets/Auto.html\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "We use the function `train_test_split()` to split\n",
        "the data into training and validation sets. As there are 392 observations,\n",
        "we split into two equal sets of size 196 using the\n",
        "argument `test_size=196`. It is generally a good idea to set a random seed\n",
        "when performing operations like this that contain an\n",
        "element of randomness, so that the results obtained can be reproduced\n",
        "precisely at a later time. We set the random seed of the splitter\n",
        "with the argument `random_state=0`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "22f44ae0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:14.147809Z",
          "iopub.status.busy": "2024-06-04T23:19:14.147730Z",
          "iopub.status.idle": "2024-06-04T23:19:14.152606Z",
          "shell.execute_reply": "2024-06-04T23:19:14.152414Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 690
        },
        "id": "22f44ae0",
        "outputId": "00fbef96-585b-40cc-f3b7-bed9c11328a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method DataFrame.info of                             mpg  cylinders  displacement  horsepower  weight  \\\n",
            "name                                                                           \n",
            "chevrolet chevelle malibu  18.0          8         307.0         130    3504   \n",
            "buick skylark 320          15.0          8         350.0         165    3693   \n",
            "plymouth satellite         18.0          8         318.0         150    3436   \n",
            "amc rebel sst              16.0          8         304.0         150    3433   \n",
            "ford torino                17.0          8         302.0         140    3449   \n",
            "...                         ...        ...           ...         ...     ...   \n",
            "ford mustang gl            27.0          4         140.0          86    2790   \n",
            "vw pickup                  44.0          4          97.0          52    2130   \n",
            "dodge rampage              32.0          4         135.0          84    2295   \n",
            "ford ranger                28.0          4         120.0          79    2625   \n",
            "chevy s-10                 31.0          4         119.0          82    2720   \n",
            "\n",
            "                           acceleration  year  origin  \n",
            "name                                                   \n",
            "chevrolet chevelle malibu          12.0    70       1  \n",
            "buick skylark 320                  11.5    70       1  \n",
            "plymouth satellite                 11.0    70       1  \n",
            "amc rebel sst                      12.0    70       1  \n",
            "ford torino                        10.5    70       1  \n",
            "...                                 ...   ...     ...  \n",
            "ford mustang gl                    15.6    82       1  \n",
            "vw pickup                          24.6    82       2  \n",
            "dodge rampage                      11.6    82       1  \n",
            "ford ranger                        18.6    82       1  \n",
            "chevy s-10                         19.4    82       1  \n",
            "\n",
            "[392 rows x 8 columns]>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.describe of                              mpg  cylinders  displacement  horsepower  weight  \\\n",
              "name                                                                            \n",
              "dodge colt                  28.0          4          90.0          75    2125   \n",
              "ford fairmont 4             22.3          4         140.0          88    2890   \n",
              "oldsmobile delta 88 royale  12.0          8         350.0         160    4456   \n",
              "plymouth horizon miser      38.0          4         105.0          63    2125   \n",
              "subaru dl                   33.8          4          97.0          67    2145   \n",
              "...                          ...        ...           ...         ...     ...   \n",
              "toyota celica gt liftback   21.1          4         134.0          95    2515   \n",
              "audi 5000                   20.3          5         131.0         103    2830   \n",
              "chevrolet concours          17.5          6         250.0         110    3520   \n",
              "ford torino 500             19.0          6         250.0          88    3302   \n",
              "amc concord d/l             18.1          6         258.0         120    3410   \n",
              "\n",
              "                            acceleration  year  origin  \n",
              "name                                                    \n",
              "dodge colt                          14.5    74       1  \n",
              "ford fairmont 4                     17.3    79       1  \n",
              "oldsmobile delta 88 royale          13.5    72       1  \n",
              "plymouth horizon miser              14.7    82       1  \n",
              "subaru dl                           18.0    80       3  \n",
              "...                                  ...   ...     ...  \n",
              "toyota celica gt liftback           14.8    78       3  \n",
              "audi 5000                           15.9    78       2  \n",
              "chevrolet concours                  16.4    77       1  \n",
              "ford torino 500                     15.5    71       1  \n",
              "amc concord d/l                     15.1    78       1  \n",
              "\n",
              "[196 rows x 8 columns]>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.generic.NDFrame.describe</b><br/>def describe(percentiles=None, include=None, exclude=None) -&gt; Self</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/pandas/core/generic.py</a>Generate descriptive statistics.\n",
              "\n",
              "Descriptive statistics include those that summarize the central\n",
              "tendency, dispersion and shape of a\n",
              "dataset&#x27;s distribution, excluding ``NaN`` values.\n",
              "\n",
              "Analyzes both numeric and object series, as well\n",
              "as ``DataFrame`` column sets of mixed data types. The output\n",
              "will vary depending on what is provided. Refer to the notes\n",
              "below for more detail.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "percentiles : list-like of numbers, optional\n",
              "    The percentiles to include in the output. All should\n",
              "    fall between 0 and 1. The default is\n",
              "    ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
              "    75th percentiles.\n",
              "include : &#x27;all&#x27;, list-like of dtypes or None (default), optional\n",
              "    A white list of data types to include in the result. Ignored\n",
              "    for ``Series``. Here are the options:\n",
              "\n",
              "    - &#x27;all&#x27; : All columns of the input will be included in the output.\n",
              "    - A list-like of dtypes : Limits the results to the\n",
              "      provided data types.\n",
              "      To limit the result to numeric types submit\n",
              "      ``numpy.number``. To limit it instead to object columns submit\n",
              "      the ``numpy.object`` data type. Strings\n",
              "      can also be used in the style of\n",
              "      ``select_dtypes`` (e.g. ``df.describe(include=[&#x27;O&#x27;])``). To\n",
              "      select pandas categorical columns, use ``&#x27;category&#x27;``\n",
              "    - None (default) : The result will include all numeric columns.\n",
              "exclude : list-like of dtypes or None (default), optional,\n",
              "    A black list of data types to omit from the result. Ignored\n",
              "    for ``Series``. Here are the options:\n",
              "\n",
              "    - A list-like of dtypes : Excludes the provided data types\n",
              "      from the result. To exclude numeric types submit\n",
              "      ``numpy.number``. To exclude object columns submit the data\n",
              "      type ``numpy.object``. Strings can also be used in the style of\n",
              "      ``select_dtypes`` (e.g. ``df.describe(exclude=[&#x27;O&#x27;])``). To\n",
              "      exclude pandas categorical columns, use ``&#x27;category&#x27;``\n",
              "    - None (default) : The result will exclude nothing.\n",
              "\n",
              "Returns\n",
              "-------\n",
              "Series or DataFrame\n",
              "    Summary statistics of the Series or Dataframe provided.\n",
              "\n",
              "See Also\n",
              "--------\n",
              "DataFrame.count: Count number of non-NA/null observations.\n",
              "DataFrame.max: Maximum of the values in the object.\n",
              "DataFrame.min: Minimum of the values in the object.\n",
              "DataFrame.mean: Mean of the values.\n",
              "DataFrame.std: Standard deviation of the observations.\n",
              "DataFrame.select_dtypes: Subset of a DataFrame including/excluding\n",
              "    columns based on their dtype.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "For numeric data, the result&#x27;s index will include ``count``,\n",
              "``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
              "upper percentiles. By default the lower percentile is ``25`` and the\n",
              "upper percentile is ``75``. The ``50`` percentile is the\n",
              "same as the median.\n",
              "\n",
              "For object data (e.g. strings or timestamps), the result&#x27;s index\n",
              "will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
              "is the most common value. The ``freq`` is the most common value&#x27;s\n",
              "frequency. Timestamps also include the ``first`` and ``last`` items.\n",
              "\n",
              "If multiple object values have the highest count, then the\n",
              "``count`` and ``top`` results will be arbitrarily chosen from\n",
              "among those with the highest count.\n",
              "\n",
              "For mixed data types provided via a ``DataFrame``, the default is to\n",
              "return only an analysis of numeric columns. If the dataframe consists\n",
              "only of object and categorical data without any numeric columns, the\n",
              "default is to return an analysis of both the object and categorical\n",
              "columns. If ``include=&#x27;all&#x27;`` is provided as an option, the result\n",
              "will include a union of attributes of each type.\n",
              "\n",
              "The `include` and `exclude` parameters can be used to limit\n",
              "which columns in a ``DataFrame`` are analyzed for the output.\n",
              "The parameters are ignored when analyzing a ``Series``.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "Describing a numeric ``Series``.\n",
              "\n",
              "&gt;&gt;&gt; s = pd.Series([1, 2, 3])\n",
              "&gt;&gt;&gt; s.describe()\n",
              "count    3.0\n",
              "mean     2.0\n",
              "std      1.0\n",
              "min      1.0\n",
              "25%      1.5\n",
              "50%      2.0\n",
              "75%      2.5\n",
              "max      3.0\n",
              "dtype: float64\n",
              "\n",
              "Describing a categorical ``Series``.\n",
              "\n",
              "&gt;&gt;&gt; s = pd.Series([&#x27;a&#x27;, &#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])\n",
              "&gt;&gt;&gt; s.describe()\n",
              "count     4\n",
              "unique    3\n",
              "top       a\n",
              "freq      2\n",
              "dtype: object\n",
              "\n",
              "Describing a timestamp ``Series``.\n",
              "\n",
              "&gt;&gt;&gt; s = pd.Series([\n",
              "...     np.datetime64(&quot;2000-01-01&quot;),\n",
              "...     np.datetime64(&quot;2010-01-01&quot;),\n",
              "...     np.datetime64(&quot;2010-01-01&quot;)\n",
              "... ])\n",
              "&gt;&gt;&gt; s.describe()\n",
              "count                      3\n",
              "mean     2006-09-01 08:00:00\n",
              "min      2000-01-01 00:00:00\n",
              "25%      2004-12-31 12:00:00\n",
              "50%      2010-01-01 00:00:00\n",
              "75%      2010-01-01 00:00:00\n",
              "max      2010-01-01 00:00:00\n",
              "dtype: object\n",
              "\n",
              "Describing a ``DataFrame``. By default only numeric fields\n",
              "are returned.\n",
              "\n",
              "&gt;&gt;&gt; df = pd.DataFrame({&#x27;categorical&#x27;: pd.Categorical([&#x27;d&#x27;, &#x27;e&#x27;, &#x27;f&#x27;]),\n",
              "...                    &#x27;numeric&#x27;: [1, 2, 3],\n",
              "...                    &#x27;object&#x27;: [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]\n",
              "...                    })\n",
              "&gt;&gt;&gt; df.describe()\n",
              "       numeric\n",
              "count      3.0\n",
              "mean       2.0\n",
              "std        1.0\n",
              "min        1.0\n",
              "25%        1.5\n",
              "50%        2.0\n",
              "75%        2.5\n",
              "max        3.0\n",
              "\n",
              "Describing all columns of a ``DataFrame`` regardless of data type.\n",
              "\n",
              "&gt;&gt;&gt; df.describe(include=&#x27;all&#x27;)  # doctest: +SKIP\n",
              "       categorical  numeric object\n",
              "count            3      3.0      3\n",
              "unique           3      NaN      3\n",
              "top              f      NaN      a\n",
              "freq             1      NaN      1\n",
              "mean           NaN      2.0    NaN\n",
              "std            NaN      1.0    NaN\n",
              "min            NaN      1.0    NaN\n",
              "25%            NaN      1.5    NaN\n",
              "50%            NaN      2.0    NaN\n",
              "75%            NaN      2.5    NaN\n",
              "max            NaN      3.0    NaN\n",
              "\n",
              "Describing a column from a ``DataFrame`` by accessing it as\n",
              "an attribute.\n",
              "\n",
              "&gt;&gt;&gt; df.numeric.describe()\n",
              "count    3.0\n",
              "mean     2.0\n",
              "std      1.0\n",
              "min      1.0\n",
              "25%      1.5\n",
              "50%      2.0\n",
              "75%      2.5\n",
              "max      3.0\n",
              "Name: numeric, dtype: float64\n",
              "\n",
              "Including only numeric columns in a ``DataFrame`` description.\n",
              "\n",
              "&gt;&gt;&gt; df.describe(include=[np.number])\n",
              "       numeric\n",
              "count      3.0\n",
              "mean       2.0\n",
              "std        1.0\n",
              "min        1.0\n",
              "25%        1.5\n",
              "50%        2.0\n",
              "75%        2.5\n",
              "max        3.0\n",
              "\n",
              "Including only string columns in a ``DataFrame`` description.\n",
              "\n",
              "&gt;&gt;&gt; df.describe(include=[object])  # doctest: +SKIP\n",
              "       object\n",
              "count       3\n",
              "unique      3\n",
              "top         a\n",
              "freq        1\n",
              "\n",
              "Including only categorical columns from a ``DataFrame`` description.\n",
              "\n",
              "&gt;&gt;&gt; df.describe(include=[&#x27;category&#x27;])\n",
              "       categorical\n",
              "count            3\n",
              "unique           3\n",
              "top              d\n",
              "freq             1\n",
              "\n",
              "Excluding numeric columns from a ``DataFrame`` description.\n",
              "\n",
              "&gt;&gt;&gt; df.describe(exclude=[np.number])  # doctest: +SKIP\n",
              "       categorical object\n",
              "count            3      3\n",
              "unique           3      3\n",
              "top              f      a\n",
              "freq             1      1\n",
              "\n",
              "Excluding object columns from a ``DataFrame`` description.\n",
              "\n",
              "&gt;&gt;&gt; df.describe(exclude=[object])  # doctest: +SKIP\n",
              "       categorical  numeric\n",
              "count            3      3.0\n",
              "unique           3      NaN\n",
              "top              f      NaN\n",
              "freq             1      NaN\n",
              "mean           NaN      2.0\n",
              "std            NaN      1.0\n",
              "min            NaN      1.0\n",
              "25%            NaN      1.5\n",
              "50%            NaN      2.0\n",
              "75%            NaN      2.5\n",
              "max            NaN      3.0</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 11734);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "Auto = load_data('Auto')\n",
        "print(Auto.info)\n",
        "\n",
        "Auto_train, Auto_valid = train_test_split(Auto,\n",
        "                                         test_size=196,\n",
        "                                         random_state=0)\n",
        "\n",
        "Auto_valid.describe\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "318fe69f",
      "metadata": {
        "id": "318fe69f"
      },
      "source": [
        "Now we can fit a linear regression using only the observations corresponding to the training set `Auto_train`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0c32e917",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:14.153847Z",
          "iopub.status.busy": "2024-06-04T23:19:14.153757Z",
          "iopub.status.idle": "2024-06-04T23:19:14.157537Z",
          "shell.execute_reply": "2024-06-04T23:19:14.157339Z"
        },
        "id": "0c32e917"
      },
      "outputs": [],
      "source": [
        "hp_mm = MS(['horsepower'])\n",
        "X_train = hp_mm.fit_transform(Auto_train)\n",
        "y_train = Auto_train['mpg']\n",
        "model = sm.OLS(y_train, X_train)\n",
        "results = model.fit()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e883b8f",
      "metadata": {
        "id": "7e883b8f"
      },
      "source": [
        "We now use the `predict()` method of `results` evaluated on the model matrix for this model\n",
        "created using the validation data set. We also calculate the validation MSE of our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "86ce4f85",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:14.158717Z",
          "iopub.status.busy": "2024-06-04T23:19:14.158637Z",
          "iopub.status.idle": "2024-06-04T23:19:14.162177Z",
          "shell.execute_reply": "2024-06-04T23:19:14.161910Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86ce4f85",
        "outputId": "8bed1e6b-4f84-4f6c-d252-2118f51a88b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(23.61661706966988)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "X_valid = hp_mm.transform(Auto_valid)\n",
        "y_valid = Auto_valid['mpg']\n",
        "valid_pred = results.predict(X_valid)\n",
        "np.mean((y_valid - valid_pred)**2) # MSE on validation dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2ecdee6",
      "metadata": {
        "id": "f2ecdee6"
      },
      "source": [
        "Hence our estimate for the validation MSE of  the linear regression\n",
        "fit is $23.62$.\n",
        "\n",
        "We can also estimate the validation error for\n",
        "higher-degree polynomial regressions. We first provide a function `evalMSE()` that takes a model string as well\n",
        "as a training and test set and returns the MSE on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "50a66a97",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:14.163466Z",
          "iopub.status.busy": "2024-06-04T23:19:14.163397Z",
          "iopub.status.idle": "2024-06-04T23:19:14.165323Z",
          "shell.execute_reply": "2024-06-04T23:19:14.165076Z"
        },
        "id": "50a66a97"
      },
      "outputs": [],
      "source": [
        "def evalMSE(terms,\n",
        "            response,\n",
        "            train,\n",
        "            test):\n",
        "\n",
        "   mm = MS(terms)\n",
        "   X_train = mm.fit_transform(train)\n",
        "   y_train = train[response]\n",
        "\n",
        "   X_test = mm.transform(test)\n",
        "   y_test = test[response]\n",
        "\n",
        "   results = sm.OLS(y_train, X_train).fit()\n",
        "   test_pred = results.predict(X_test)\n",
        "\n",
        "   return np.mean((y_test - test_pred)**2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a255779c",
      "metadata": {
        "id": "a255779c"
      },
      "source": [
        "Let’s use this function to estimate the validation MSE\n",
        "using linear, quadratic and cubic fits. We use the `enumerate()`  function\n",
        "here, which gives both the values and indices of objects as one iterates\n",
        "over a for loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "d49b6999",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:14.166563Z",
          "iopub.status.busy": "2024-06-04T23:19:14.166497Z",
          "iopub.status.idle": "2024-06-04T23:19:14.177198Z",
          "shell.execute_reply": "2024-06-04T23:19:14.176975Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d49b6999",
        "outputId": "1125810c-8cd9-49be-a2ce-f65bb6109f8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([20.75540796, 16.94510676, 16.97437833])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "#help(enumerate)\n",
        "\n",
        "MSE = np.zeros(3)\n",
        "for idx, degree in enumerate(range(1, 4)):\n",
        "    MSE[idx] = evalMSE([poly('horsepower', degree)],\n",
        "                       'mpg',\n",
        "                       Auto_train,\n",
        "                       Auto_valid)\n",
        "MSE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d7b8fc1",
      "metadata": {
        "id": "9d7b8fc1"
      },
      "source": [
        "These error rates are $23.62, 18.76$, and $18.80$, respectively. If we\n",
        "choose a different training/validation split instead, then we\n",
        "can expect somewhat different errors on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "dac8bd54",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:14.178405Z",
          "iopub.status.busy": "2024-06-04T23:19:14.178321Z",
          "iopub.status.idle": "2024-06-04T23:19:14.188650Z",
          "shell.execute_reply": "2024-06-04T23:19:14.188432Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dac8bd54",
        "outputId": "73de0653-1a2b-4150-c451-fed800217fe8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([20.75540796, 16.94510676, 16.97437833])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "Auto_train, Auto_valid = train_test_split(Auto,\n",
        "                                          test_size=196,\n",
        "                                          random_state=3)\n",
        "MSE = np.zeros(3)\n",
        "for idx, degree in enumerate(range(1, 4)):\n",
        "    MSE[idx] = evalMSE([poly('horsepower', degree)],\n",
        "                       'mpg',\n",
        "                       Auto_train,\n",
        "                       Auto_valid)\n",
        "MSE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61f2c12d",
      "metadata": {
        "id": "61f2c12d"
      },
      "source": [
        "Using this split of the observations into a training set and a validation set,\n",
        "we find that the validation set error rates for the models with linear, quadratic, and cubic terms are $20.76$, $16.95$, and $16.97$, respectively.\n",
        "\n",
        "These results are consistent with our previous findings: a model that\n",
        "predicts `mpg` using a quadratic function of `horsepower`\n",
        "performs better than a model that involves only a linear function of\n",
        "`horsepower`, and there is no evidence of an improvement in using a cubic function of `horsepower`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f22daa51",
      "metadata": {
        "id": "f22daa51"
      },
      "source": [
        "## Cross-Validation\n",
        "In theory, the cross-validation estimate can be computed for any generalized\n",
        "linear model.  {}\n",
        "In practice, however, the simplest way to cross-validate in\n",
        "Python is to use `sklearn`, which has a different interface or API\n",
        "than `statsmodels`, the code we have been using to fit GLMs.\n",
        "\n",
        "This is a problem which often confronts data scientists: \"I have a function to do task $A$, and need to feed it into something that performs task $B$, so that I can compute $B(A(D))$, where $D$ is my data.\" When $A$ and $B$ don’t naturally speak to each other, this\n",
        "requires the use of a *wrapper*.\n",
        "In the `ISLP` package,\n",
        "we provide\n",
        "a wrapper, `sklearn_sm()`, that enables us to easily use the cross-validation tools of `sklearn` with\n",
        "models fit by `statsmodels`.\n",
        "\n",
        "The class `sklearn_sm()`\n",
        "has  as its first argument\n",
        "a model from `statsmodels`. It can take two additional\n",
        "optional arguments: `model_str` which can be\n",
        "used to specify a formula, and `model_args` which should\n",
        "be a dictionary of additional arguments used when fitting\n",
        "the model. For example, to fit a logistic regression model\n",
        "we have to specify a `family` argument. This\n",
        "is passed as `model_args={'family':sm.families.Binomial()}`.\n",
        "\n",
        "Here is our wrapper in action:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "601ae443",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:14.189993Z",
          "iopub.status.busy": "2024-06-04T23:19:14.189906Z",
          "iopub.status.idle": "2024-06-04T23:19:14.876368Z",
          "shell.execute_reply": "2024-06-04T23:19:14.876129Z"
        },
        "lines_to_next_cell": 0,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "601ae443",
        "outputId": "dde6213b-1d5f-473f-aa9a-7dec33a98ba5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "392\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(24.23151351792922)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "\n",
        "hp_model = sklearn_sm(sm.OLS,\n",
        "                      MS(['horsepower']))\n",
        "X, Y = Auto.drop(columns=['mpg']), Auto['mpg']\n",
        "\n",
        "# help(cross_validate)\n",
        "print(Auto.shape[0])\n",
        "cv_results = cross_validate(hp_model,\n",
        "                            X,\n",
        "                            Y,\n",
        "                            cv=Auto.shape[0]  # 392 rows (Determines the cross-validation splitting strategy)\n",
        "                            )\n",
        "# print(cv_results)\n",
        "cv_err = np.mean(cv_results['test_score'])\n",
        "cv_err\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebadc35f",
      "metadata": {
        "id": "ebadc35f"
      },
      "source": [
        "The arguments to `cross_validate()` are as follows: an\n",
        "object with the appropriate `fit()`, `predict()`,\n",
        "and `score()` methods,  an\n",
        "array of features `X` and a response `Y`.\n",
        "We also included an additional argument `cv` to `cross_validate()`; specifying an integer\n",
        "$K$ results in $K$-fold cross-validation. We have provided a value\n",
        "corresponding to the total number of observations, which results in\n",
        "leave-one-out cross-validation (LOOCV). The `cross_validate()`  function produces a dictionary with several components;\n",
        "we simply want the cross-validated test score here (MSE), which is estimated to be 24.23."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25f47b99",
      "metadata": {
        "id": "25f47b99"
      },
      "source": [
        "We can repeat this procedure for increasingly complex polynomial fits.\n",
        "To automate the process, we again\n",
        "use a for loop which iteratively fits polynomial\n",
        "regressions of degree 1 to 5, computes the\n",
        "associated cross-validation error, and stores it in the $i$th element\n",
        "of the vector `cv_error`. The variable `d` in the for loop\n",
        "corresponds to the degree of the polynomial. We begin by initializing the\n",
        "vector. This command may take a couple of seconds to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "11226c85",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:14.877800Z",
          "iopub.status.busy": "2024-06-04T23:19:14.877726Z",
          "iopub.status.idle": "2024-06-04T23:19:15.384419Z",
          "shell.execute_reply": "2024-06-04T23:19:15.384193Z"
        },
        "lines_to_next_cell": 0,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11226c85",
        "outputId": "24e76b2e-6a76-42ab-a9c8-2258bb687827"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([24.23151352, 19.24821312, 19.33498406, 19.42443029, 19.03320648])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "cv_error = np.zeros(5)\n",
        "H = np.array(Auto['horsepower'])\n",
        "M = sklearn_sm(sm.OLS)\n",
        "\n",
        "# help(np.power.outer)\n",
        "# Loop over polynomial degrees from 1 to 5 using 'enumerate' to get both the index 'i' and degree 'd'\n",
        "for i, d in enumerate(range(1,6)):\n",
        "\n",
        "    # np.power.outer(H, np.arange(d+1)) generates [1, H, H^2, ..., H^d] for each data point\n",
        "    X = np.power.outer(H, np.arange(d+1))\n",
        "\n",
        "    # Perform cross-validation using the design matrix X and target variable Y\n",
        "    M_CV = cross_validate(M,\n",
        "                          X,\n",
        "                          Y,\n",
        "                          cv=Auto.shape[0]) # implies leave-one-out cross-validation, where each sample is used as a test set once\n",
        "\n",
        "    # Compute the mean of the cross-validation scores and store it in the cv_error array\n",
        "    cv_error[i] = np.mean(M_CV['test_score'])\n",
        "cv_error\n",
        "\n",
        "#print(X)\n",
        "#print(H)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.power.outer?"
      ],
      "metadata": {
        "id": "hdAg7bU8GDy1"
      },
      "id": "hdAg7bU8GDy1",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a3a920ae",
      "metadata": {
        "id": "a3a920ae"
      },
      "source": [
        "As in Figure~\\ref{Ch5:cvplot}, we see a sharp drop in the estimated test MSE between the linear and\n",
        "quadratic fits, but then no clear improvement from using higher-degree polynomials.\n",
        "\n",
        "Above we introduced the `outer()`  method of the `np.power()`\n",
        "function.  The `outer()` method is applied to an operation\n",
        "that has two arguments, such as `add()`, `min()`, or\n",
        "`power()`.\n",
        "It has two arrays as\n",
        "arguments, and then forms a larger\n",
        "array where the operation is applied to each pair of elements of the\n",
        "two arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "64b64d97",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:15.385768Z",
          "iopub.status.busy": "2024-06-04T23:19:15.385690Z",
          "iopub.status.idle": "2024-06-04T23:19:15.387686Z",
          "shell.execute_reply": "2024-06-04T23:19:15.387484Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64b64d97",
        "outputId": "f2e3cbe0-2393-4ca7-ecc4-ea194b6dddd3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5,  7],\n",
              "       [ 7,  9],\n",
              "       [11, 13]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "A = np.array([3, 5, 9])\n",
        "B = np.array([2, 4])\n",
        "np.add.outer(A, B)\n",
        "\n",
        "# help(np.outer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71385c1b",
      "metadata": {
        "id": "71385c1b"
      },
      "source": [
        "In the CV example above, we used $K=n$, but of course we can also use $K<n$. The code is very similar\n",
        "to the above (and is significantly faster). Here we use `KFold()` to partition the data into $K=10$ random groups. We use `random_state` to set a random seed and initialize a vector `cv_error` in which we will store the CV errors corresponding to the\n",
        "polynomial fits of degrees one to five."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ca0f972f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:15.389014Z",
          "iopub.status.busy": "2024-06-04T23:19:15.388934Z",
          "iopub.status.idle": "2024-06-04T23:19:15.407438Z",
          "shell.execute_reply": "2024-06-04T23:19:15.407194Z"
        },
        "lines_to_next_cell": 0,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca0f972f",
        "outputId": "32846a33-7f1d-4f60-cad6-ee7657b572a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([24.20766449, 19.18533142, 19.27626666, 19.47848403, 19.13720065])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "cv_error = np.zeros(5)\n",
        "\n",
        "# help(KFold)\n",
        "\n",
        "cv = KFold(n_splits=10,\n",
        "           shuffle=True,   # Whether to shuffle the data before splitting into batches. Note that the samples within each split will not be shuffled.\n",
        "           random_state=0) # use same splits for each degree. When `shuffle` is True, `random_state` affects the ordering of the indices, which controls the randomness of each fold. Otherwise, this parameter has no effect\n",
        "\n",
        "# print(cv)\n",
        "\n",
        "for i, d in enumerate(range(1,6)):\n",
        "\n",
        "    X = np.power.outer(H, np.arange(d+1))\n",
        "\n",
        "    M_CV = cross_validate(M,\n",
        "                          X,\n",
        "                          Y,\n",
        "                          cv=cv)\n",
        "\n",
        "    cv_error[i] = np.mean(M_CV['test_score'])\n",
        "\n",
        "cv_error\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b234093",
      "metadata": {
        "id": "8b234093"
      },
      "source": [
        "Notice that the computation time is much shorter than that of LOOCV.\n",
        "(In principle, the computation time for LOOCV for a least squares\n",
        "linear model should be faster than for $K$-fold CV, due to the\n",
        "availability of the formula~(\\ref{Ch5:eq:LOOCVform})  for LOOCV;\n",
        "however, the generic `cross_validate()`  function does not make\n",
        "use of this formula.)  We still see little evidence that using cubic\n",
        "or higher-degree polynomial terms leads to a lower test error than simply\n",
        "using a quadratic fit."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb4487a4",
      "metadata": {
        "id": "fb4487a4"
      },
      "source": [
        "The `cross_validate()` function is flexible and can take\n",
        "different splitting mechanisms as an argument. For instance, one can use the `ShuffleSplit()` funtion to implement\n",
        "the validation set approach just as easily as K-fold cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "080cdb29",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:15.408750Z",
          "iopub.status.busy": "2024-06-04T23:19:15.408677Z",
          "iopub.status.idle": "2024-06-04T23:19:15.413979Z",
          "shell.execute_reply": "2024-06-04T23:19:15.413762Z"
        },
        "lines_to_next_cell": 2,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "080cdb29",
        "outputId": "fa08f084-a361-472c-8c46-398d1750a282"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([23.61661707])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# help(ShuffleSplit)\n",
        "\n",
        "validation = ShuffleSplit(n_splits=1,\n",
        "                          test_size=196,\n",
        "                          random_state=0)\n",
        "\n",
        "results = cross_validate(hp_model,\n",
        "                         Auto.drop(['mpg'], axis=1),\n",
        "                         Auto['mpg'],\n",
        "                         cv=validation);\n",
        "\n",
        "results['test_score']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d07e8ef7",
      "metadata": {
        "id": "d07e8ef7"
      },
      "source": [
        "https://amueller.github.io/aml/04-model-evaluation/1-data-splitting-strategies.html\n",
        "\n",
        "![image-2.png](attachment:image-2.png)\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2f4b4cf",
      "metadata": {
        "id": "b2f4b4cf"
      },
      "source": [
        "One can estimate the variability in the test error by running the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "7c46de2b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:15.415225Z",
          "iopub.status.busy": "2024-06-04T23:19:15.415158Z",
          "iopub.status.idle": "2024-06-04T23:19:15.437526Z",
          "shell.execute_reply": "2024-06-04T23:19:15.437302Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c46de2b",
        "outputId": "ad679811-d78e-4b7e-a09d-629bc7a1a467"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(23.802232661034168), np.float64(1.4218450941091842))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "validation = ShuffleSplit(n_splits=10,\n",
        "                          test_size=196,\n",
        "                          random_state=0)\n",
        "results = cross_validate(hp_model,\n",
        "                         Auto.drop(['mpg'], axis=1),\n",
        "                         Auto['mpg'],\n",
        "                         cv=validation)\n",
        "results['test_score'].mean(), results['test_score'].std()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07165f0e",
      "metadata": {
        "id": "07165f0e"
      },
      "source": [
        "Note that this standard deviation is not a valid estimate of the\n",
        "sampling variability of the mean test score or the individual scores, since the randomly-selected training\n",
        "samples overlap and hence introduce correlations. But it does give an\n",
        "idea of the Monte Carlo variation\n",
        "incurred by picking different random folds.\n",
        "\n",
        "## The Bootstrap\n",
        "We illustrate the use of the bootstrap in the simple example\n",
        " {of Section~\\ref{Ch5:sec:bootstrap},}  as well as on an example involving\n",
        "estimating the accuracy of the linear regression model on the  `Auto`\n",
        "data set.\n",
        "### Estimating the Accuracy of a Statistic of Interest\n",
        "One of the great advantages of the bootstrap approach is that it can\n",
        "be applied in almost all situations. No complicated mathematical\n",
        "calculations are required. While there are several implementations\n",
        "of the bootstrap in Python, its use for estimating\n",
        "standard error is simple enough that we write our own function\n",
        "below for the case when our data is stored\n",
        "in a dataframe.\n",
        "\n",
        "https://islp.readthedocs.io/en/latest/datasets/Portfolio.html\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "To illustrate the bootstrap, we\n",
        "start with a simple example.\n",
        "The  `Portfolio`  data set in the `ISLP` package is described\n",
        "in Section~\\ref{Ch5:sec:bootstrap}. The goal is to estimate the\n",
        "sampling variance of the parameter $\\alpha$ given in formula~(\\ref{Ch5:min.var}).  We will\n",
        "create a function\n",
        "`alpha_func()`, which takes as input a dataframe `D` assumed\n",
        "to have columns `X` and `Y`, as well as a\n",
        "vector `idx` indicating which observations should be used to\n",
        "estimate\n",
        "$\\alpha$. The function then outputs the estimate for $\\alpha$ based on\n",
        "the selected observations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "a4b6d9b3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:15.438786Z",
          "iopub.status.busy": "2024-06-04T23:19:15.438714Z",
          "iopub.status.idle": "2024-06-04T23:19:15.441484Z",
          "shell.execute_reply": "2024-06-04T23:19:15.441268Z"
        },
        "lines_to_next_cell": 0,
        "id": "a4b6d9b3"
      },
      "outputs": [],
      "source": [
        "Portfolio = load_data('Portfolio')\n",
        "\n",
        "def alpha_func(D, idx):\n",
        "   cov_ = np.cov(D[['X','Y']].loc[idx], rowvar=False)\n",
        "   #print(cov_)\n",
        "   return ((cov_[1,1] - cov_[0,1]) /\n",
        "           (cov_[0,0]+cov_[1,1]-2*cov_[0,1]))\n",
        "\n",
        "\n",
        "def alpha_func(D, idx):\n",
        "    # Calculate the covariance matrix of columns 'X' and 'Y' from DataFrame D, using only the rows specified by the indices in idx.\n",
        "    # 'rowvar=False' ensures that each column is treated as a variable, and rows correspond to observations.\n",
        "    cov_ = np.cov(D[['X', 'Y']].loc[idx], rowvar=False)\n",
        "\n",
        "    # Return the calculated alpha value, which measures the difference between the variances of 'X' and 'Y' relative to their covariance.\n",
        "    # The formula is: (Variance of Y - Covariance between X and Y) / (Variance of X + Variance of Y - 2 * Covariance between X and Y)\n",
        "    return ((cov_[1, 1] - cov_[0, 1]) /\n",
        "            (cov_[0, 0] + cov_[1, 1] - 2 * cov_[0, 1]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d50058e",
      "metadata": {
        "id": "9d50058e"
      },
      "source": [
        "This function returns an estimate for $\\alpha$\n",
        "based on applying the minimum\n",
        "    variance formula (\\ref{Ch5:min.var}) to the observations indexed by\n",
        "the argument `idx`.  For instance, the following command\n",
        "estimates $\\alpha$ using all 100 observations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "81498a11",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:15.442843Z",
          "iopub.status.busy": "2024-06-04T23:19:15.442765Z",
          "iopub.status.idle": "2024-06-04T23:19:15.445171Z",
          "shell.execute_reply": "2024-06-04T23:19:15.444944Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81498a11",
        "outputId": "820f999a-afd6-474c-91e6-256a0dc799be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.57583207459283)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "alpha_func(Portfolio, range(100))\n",
        "\n",
        "# print((1.30823747-0.62635829)/(1.12864236+1.30823747-2*0.62635829))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f5d0aab",
      "metadata": {
        "id": "4f5d0aab"
      },
      "source": [
        "Next we randomly select\n",
        "100 observations from `range(100)`, with replacement. This is equivalent\n",
        "to constructing a new bootstrap data set and recomputing $\\hat{\\alpha}$\n",
        "based on the new data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "64fe1cb6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:15.446422Z",
          "iopub.status.busy": "2024-06-04T23:19:15.446354Z",
          "iopub.status.idle": "2024-06-04T23:19:15.448793Z",
          "shell.execute_reply": "2024-06-04T23:19:15.448579Z"
        },
        "lines_to_next_cell": 2,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64fe1cb6",
        "outputId": "cc2a9b7e-ea98-42ac-c322-16086c73c7a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator(PCG64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.6074452469619004)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# help(np.random.default_rng)\n",
        "# rng.choice(100,100)\n",
        "rng= np.random.default_rng(0)\n",
        "print(rng)\n",
        "\n",
        "alpha_func(\n",
        "    Portfolio,\n",
        "    rng.choice(\n",
        "        100,       # Randomly select from numbers between 0 and 99 (inclusive)\n",
        "        100,       # Draw 100 samples\n",
        "        replace=True  # Allow drawing the same number more than once (sampling with replacement)\n",
        "    )\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91a635fe",
      "metadata": {
        "id": "91a635fe"
      },
      "source": [
        "This process can be generalized to create a simple function `boot_SE()` for\n",
        "computing the bootstrap standard error for arbitrary\n",
        "functions that take only a data frame as an argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "dd16bbae",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:15.450062Z",
          "iopub.status.busy": "2024-06-04T23:19:15.449992Z",
          "iopub.status.idle": "2024-06-04T23:19:15.451958Z",
          "shell.execute_reply": "2024-06-04T23:19:15.451742Z"
        },
        "lines_to_next_cell": 0,
        "id": "dd16bbae"
      },
      "outputs": [],
      "source": [
        "def boot_SE(func,\n",
        "            D,\n",
        "            n=None,\n",
        "            B=1000,\n",
        "            seed=0):\n",
        "\n",
        "    # Initialize the random number generator with a specified seed for reproducibility and other accmulators\n",
        "    rng = np.random.default_rng(seed)\n",
        "    first_, second_ = 0, 0\n",
        "\n",
        "    # Set 'n' to the number of rows in D if 'n' is not provided\n",
        "    n = n or D.shape[0]\n",
        "\n",
        "    # Perform bootstrapping B times\n",
        "    for _ in range(B):\n",
        "\n",
        "        # Randomly select 'n' indices from the DataFrame D, with replacement\n",
        "        idx = rng.choice(D.index,\n",
        "                         n,\n",
        "                         replace=True)\n",
        "\n",
        "        # Apply the provided function 'func' to the DataFrame D, using the sampled indices\n",
        "        value = func(D, idx)\n",
        "\n",
        "        # Accumulate the value and the square of the value\n",
        "        first_ += value\n",
        "        second_ += value**2\n",
        "\n",
        "    # Calculate the standard error using the formula for the standard deviation\n",
        "    return np.sqrt(second_ / B - (first_ / B)**2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bb05c52",
      "metadata": {
        "id": "1bb05c52"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac4e17ed",
      "metadata": {
        "id": "ac4e17ed"
      },
      "source": [
        "Notice the use of `_` as a loop variable in `for _ in range(B)`. This is often used if the value of the counter is\n",
        "unimportant and simply makes sure  the loop is executed `B` times.\n",
        "\n",
        "Let’s use our function to evaluate the accuracy of our\n",
        "estimate of $\\alpha$ using $B=1{,}000$ bootstrap replications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "b42b4585",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:15.453190Z",
          "iopub.status.busy": "2024-06-04T23:19:15.453118Z",
          "iopub.status.idle": "2024-06-04T23:19:15.631597Z",
          "shell.execute_reply": "2024-06-04T23:19:15.631370Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b42b4585",
        "outputId": "3f111c88-7d88-4903-f99d-9b7e82df52c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.09118176521277699)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "alpha_SE = boot_SE(alpha_func,\n",
        "                   Portfolio,\n",
        "                   B=1000,\n",
        "                   seed=0)\n",
        "alpha_SE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c5464d7",
      "metadata": {
        "id": "6c5464d7"
      },
      "source": [
        "The final output shows that the bootstrap estimate for ${\\rm SE}(\\hat{\\alpha})$ is $0.0912$.\n",
        "\n",
        "### Estimating the Accuracy of a Linear Regression Model\n",
        "The bootstrap approach can be used to assess the variability of the\n",
        "coefficient estimates and predictions from a statistical learning\n",
        "method. Here we use the bootstrap approach in order to assess the\n",
        "variability of the estimates for $\\beta_0$ and $\\beta_1$, the\n",
        "intercept and slope terms for the linear regression model that uses\n",
        "`horsepower` to predict `mpg` in the  `Auto`  data set. We\n",
        "will compare the estimates obtained using the bootstrap to those\n",
        "obtained using the formulas for ${\\rm SE}(\\hat{\\beta}_0)$ and\n",
        "${\\rm SE}(\\hat{\\beta}_1)$ described in Section~\\ref{Ch3:secoefsec}.\n",
        "\n",
        "To use our `boot_SE()` function, we must write a function (its\n",
        "first argument)\n",
        "that takes a data frame `D` and indices `idx`\n",
        "as its only arguments. But here we want to bootstrap a specific\n",
        "regression model, specified by a model formula and data. We show how\n",
        "to do this in a few simple steps.\n",
        "\n",
        "We start by writing a generic\n",
        "function `boot_OLS()` for bootstrapping a regression model that takes a formula to\n",
        "define the corresponding regression. We use the `clone()` function to\n",
        "make a copy of the formula that can be refit to the new dataframe. This means\n",
        "that any derived features such as those defined by `poly()`\n",
        "(which we will see shortly),\n",
        "will be re-fit on the resampled data frame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "6bc11784",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:15.632802Z",
          "iopub.status.busy": "2024-06-04T23:19:15.632725Z",
          "iopub.status.idle": "2024-06-04T23:19:15.634450Z",
          "shell.execute_reply": "2024-06-04T23:19:15.634222Z"
        },
        "lines_to_next_cell": 0,
        "id": "6bc11784"
      },
      "outputs": [],
      "source": [
        "def boot_OLS(model_matrix, response, D, idx):\n",
        "    D_ = D.loc[idx]\n",
        "    Y_ = D_[response]\n",
        "    X_ = clone(model_matrix).fit_transform(D_)\n",
        "    return sm.OLS(Y_, X_).fit().params"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a6ea3ce",
      "metadata": {
        "id": "2a6ea3ce"
      },
      "source": [
        "This is not quite what is needed as the first argument to\n",
        "`boot_SE()`. The first two arguments which specify the model will not change in the\n",
        "bootstrap process, and we would like to *freeze* them.   The\n",
        "function `partial()` from the `functools` module  does precisely this: it takes a function\n",
        "as an argument, and freezes some of its arguments, starting from the\n",
        "left. We use it to freeze the first two model-formula arguments of `boot_OLS()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "740cd50c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:15.635644Z",
          "iopub.status.busy": "2024-06-04T23:19:15.635575Z",
          "iopub.status.idle": "2024-06-04T23:19:15.637097Z",
          "shell.execute_reply": "2024-06-04T23:19:15.636867Z"
        },
        "lines_to_next_cell": 0,
        "id": "740cd50c"
      },
      "outputs": [],
      "source": [
        "hp_func = partial(boot_OLS, MS(['horsepower']), 'mpg')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed6d19e2",
      "metadata": {
        "id": "ed6d19e2"
      },
      "source": [
        "Typing `hp_func?` will show that it has two arguments `D`\n",
        "and `idx` --- it is a version of `boot_OLS()` with the first\n",
        "two arguments frozen --- and hence is ideal as the first argument for `boot_SE()`.\n",
        "\n",
        "The `hp_func()` function can now be used in order to create\n",
        "bootstrap estimates for the intercept and slope terms by randomly\n",
        "sampling from among the observations with replacement. We first\n",
        "demonstrate its utility on 10 bootstrap samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "ffb3ec50",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:15.638287Z",
          "iopub.status.busy": "2024-06-04T23:19:15.638220Z",
          "iopub.status.idle": "2024-06-04T23:19:15.656475Z",
          "shell.execute_reply": "2024-06-04T23:19:15.656261Z"
        },
        "lines_to_next_cell": 0,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffb3ec50",
        "outputId": "d0c87763-8792-4cd4-9ad8-4e2210b92547"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[39.12226577, -0.1555926 ],\n",
              "       [37.18648613, -0.13915813],\n",
              "       [37.46989244, -0.14112749],\n",
              "       [38.56723252, -0.14830116],\n",
              "       [38.95495707, -0.15315141],\n",
              "       [39.12563927, -0.15261044],\n",
              "       [38.45763251, -0.14767251],\n",
              "       [38.43372587, -0.15019447],\n",
              "       [37.87581142, -0.1409544 ],\n",
              "       [37.95949036, -0.1451333 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "rng = np.random.default_rng(0)\n",
        "np.array([hp_func(Auto,\n",
        "          rng.choice(Auto.index,\n",
        "                     392,\n",
        "                     replace=True)) for _ in range(10)])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6d09d96",
      "metadata": {
        "id": "c6d09d96"
      },
      "source": [
        "Next, we use the `boot_SE()` {}  function to compute the standard\n",
        "errors of 1,000 bootstrap estimates for the intercept and slope terms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "7d561f70",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:15.657733Z",
          "iopub.status.busy": "2024-06-04T23:19:15.657659Z",
          "iopub.status.idle": "2024-06-04T23:19:17.204871Z",
          "shell.execute_reply": "2024-06-04T23:19:17.204614Z"
        },
        "lines_to_next_cell": 2,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "7d561f70",
        "outputId": "b236bd80-3a14-4ed5-9c9a-1e61403965ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "intercept     0.731176\n",
              "horsepower    0.006092\n",
              "dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>intercept</th>\n",
              "      <td>0.731176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>horsepower</th>\n",
              "      <td>0.006092</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "hp_se = boot_SE(hp_func,\n",
        "                Auto,\n",
        "                B=1000,\n",
        "                seed=10)\n",
        "hp_se\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a834f240",
      "metadata": {
        "id": "a834f240"
      },
      "source": [
        "This indicates that the bootstrap estimate for ${\\rm SE}(\\hat{\\beta}_0)$ is\n",
        "0.85, and that the bootstrap\n",
        "estimate for ${\\rm SE}(\\hat{\\beta}_1)$ is\n",
        "0.0074.  As discussed in\n",
        "Section~\\ref{Ch3:secoefsec}, standard formulas can be used to compute\n",
        "the standard errors for the regression coefficients in a linear\n",
        "model. These can be obtained using the `summarize()`  function\n",
        "from `ISLP.sm`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "3888aa0a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:17.206302Z",
          "iopub.status.busy": "2024-06-04T23:19:17.206223Z",
          "iopub.status.idle": "2024-06-04T23:19:17.221631Z",
          "shell.execute_reply": "2024-06-04T23:19:17.221444Z"
        },
        "lines_to_next_cell": 2,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "3888aa0a",
        "outputId": "42b6c282-288a-43db-fd6a-689eda79b894"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "intercept     0.717\n",
              "horsepower    0.006\n",
              "Name: std err, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>std err</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>intercept</th>\n",
              "      <td>0.717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>horsepower</th>\n",
              "      <td>0.006</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "hp_model.fit(Auto, Auto['mpg'])\n",
        "model_se = summarize(hp_model.results_)['std err']\n",
        "model_se\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aefc0575",
      "metadata": {
        "id": "aefc0575"
      },
      "source": [
        "The standard error estimates for $\\hat{\\beta}_0$ and $\\hat{\\beta}_1$\n",
        "obtained using the formulas  from Section~\\ref{Ch3:secoefsec}  are\n",
        "0.717 for the\n",
        "intercept and\n",
        "0.006 for the\n",
        "slope. Interestingly, these are somewhat different from the estimates\n",
        "obtained using the bootstrap.  Does this indicate a problem with the\n",
        "bootstrap? In fact, it suggests the opposite.  Recall that the\n",
        "standard formulas given in\n",
        " {Equation~\\ref{Ch3:se.eqn} on page~\\pageref{Ch3:se.eqn}}\n",
        "rely on certain assumptions. For example,\n",
        "they depend on the unknown parameter $\\sigma^2$, the noise\n",
        "variance. We then estimate $\\sigma^2$ using the RSS. Now although the\n",
        "formula for the standard errors do not rely on the linear model being\n",
        "correct, the estimate for $\\sigma^2$ does.  We see\n",
        " {in Figure~\\ref{Ch3:polyplot} on page~\\pageref{Ch3:polyplot}}  that there is\n",
        "a non-linear relationship in the data, and so the residuals from a\n",
        "linear fit will be inflated, and so will $\\hat{\\sigma}^2$.  Secondly,\n",
        "the standard formulas assume (somewhat unrealistically) that the $x_i$\n",
        "are fixed, and all the variability comes from the variation in the\n",
        "errors $\\epsilon_i$.  The bootstrap approach does not rely on any of\n",
        "these assumptions, and so it is likely giving a more accurate estimate\n",
        "of the standard errors of $\\hat{\\beta}_0$ and $\\hat{\\beta}_1$ than\n",
        "the results from `sm.OLS`.\n",
        "\n",
        "Below we compute the bootstrap standard error estimates and the\n",
        "standard linear regression estimates that result from fitting the\n",
        "quadratic model to the data. Since this model provides a good fit to\n",
        "the data (Figure~\\ref{Ch3:polyplot}), there is now a better\n",
        "correspondence between the bootstrap estimates and the standard\n",
        "estimates of ${\\rm SE}(\\hat{\\beta}_0)$, ${\\rm SE}(\\hat{\\beta}_1)$ and\n",
        "${\\rm SE}(\\hat{\\beta}_2)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "acc3e32c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:17.222887Z",
          "iopub.status.busy": "2024-06-04T23:19:17.222785Z",
          "iopub.status.idle": "2024-06-04T23:19:19.351574Z",
          "shell.execute_reply": "2024-06-04T23:19:19.351317Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "acc3e32c",
        "outputId": "63e4dfdd-3e1e-4762-ff5f-2ed6de91538e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "intercept                                  1.538641\n",
              "poly(horsepower, degree=2, raw=True)[0]    0.024696\n",
              "poly(horsepower, degree=2, raw=True)[1]    0.000090\n",
              "dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>intercept</th>\n",
              "      <td>1.538641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>poly(horsepower, degree=2, raw=True)[0]</th>\n",
              "      <td>0.024696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>poly(horsepower, degree=2, raw=True)[1]</th>\n",
              "      <td>0.000090</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "quad_model = MS([poly('horsepower', 2, raw=True)])\n",
        "quad_func = partial(boot_OLS,\n",
        "                    quad_model,\n",
        "                    'mpg')\n",
        "boot_SE(quad_func, Auto, B=1000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8a2fd2b",
      "metadata": {
        "id": "e8a2fd2b"
      },
      "source": [
        "We  compare the results to the standard errors computed using `sm.OLS()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "dca5340c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:19.352904Z",
          "iopub.status.busy": "2024-06-04T23:19:19.352827Z",
          "iopub.status.idle": "2024-06-04T23:19:19.360147Z",
          "shell.execute_reply": "2024-06-04T23:19:19.359948Z"
        },
        "lines_to_next_cell": 0,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "dca5340c",
        "outputId": "3df941f2-2037-491a-aa72-074080560d74"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "intercept                                  1.800\n",
              "poly(horsepower, degree=2, raw=True)[0]    0.031\n",
              "poly(horsepower, degree=2, raw=True)[1]    0.000\n",
              "Name: std err, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>std err</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>intercept</th>\n",
              "      <td>1.800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>poly(horsepower, degree=2, raw=True)[0]</th>\n",
              "      <td>0.031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>poly(horsepower, degree=2, raw=True)[1]</th>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "M = sm.OLS(Auto['mpg'],\n",
        "           quad_model.fit_transform(Auto))\n",
        "summarize(M.fit())['std err']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e98297be",
      "metadata": {
        "id": "e98297be"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab\n"
      ],
      "metadata": {
        "id": "1yY70uIhLhb5"
      },
      "id": "1yY70uIhLhb5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 5.3.1: Modified Validation Set Approach\n",
        "\n",
        "Select a random training set (without replacement) of 250 observations out of the original 392 observations in the Auto data set with 'random_state=10'. Fit linear, quadratic, and cubic regressions to the 250 observations in the training set and then calculate the MSE of the other 142 observations in the validation set. Enter the values of estimated test MSE to the linear, quadratic, and cubic regression models (round to two decimal places)."
      ],
      "metadata": {
        "id": "biH9AuTcMjVH"
      },
      "id": "biH9AuTcMjVH"
    },
    {
      "cell_type": "code",
      "source": [
        "Auto = load_data('Auto')\n",
        "print(Auto.info)\n",
        "\n",
        "Auto_train, Auto_valid = train_test_split(Auto,\n",
        "                                         test_size=142,\n",
        "                                         random_state=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2y8cMUZLnzx",
        "outputId": "50965f27-4a97-4e7c-b24c-adc2f35982c3"
      },
      "id": "U2y8cMUZLnzx",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method DataFrame.info of                             mpg  cylinders  displacement  horsepower  weight  \\\n",
            "name                                                                           \n",
            "chevrolet chevelle malibu  18.0          8         307.0         130    3504   \n",
            "buick skylark 320          15.0          8         350.0         165    3693   \n",
            "plymouth satellite         18.0          8         318.0         150    3436   \n",
            "amc rebel sst              16.0          8         304.0         150    3433   \n",
            "ford torino                17.0          8         302.0         140    3449   \n",
            "...                         ...        ...           ...         ...     ...   \n",
            "ford mustang gl            27.0          4         140.0          86    2790   \n",
            "vw pickup                  44.0          4          97.0          52    2130   \n",
            "dodge rampage              32.0          4         135.0          84    2295   \n",
            "ford ranger                28.0          4         120.0          79    2625   \n",
            "chevy s-10                 31.0          4         119.0          82    2720   \n",
            "\n",
            "                           acceleration  year  origin  \n",
            "name                                                   \n",
            "chevrolet chevelle malibu          12.0    70       1  \n",
            "buick skylark 320                  11.5    70       1  \n",
            "plymouth satellite                 11.0    70       1  \n",
            "amc rebel sst                      12.0    70       1  \n",
            "ford torino                        10.5    70       1  \n",
            "...                                 ...   ...     ...  \n",
            "ford mustang gl                    15.6    82       1  \n",
            "vw pickup                          24.6    82       2  \n",
            "dodge rampage                      11.6    82       1  \n",
            "ford ranger                        18.6    82       1  \n",
            "chevy s-10                         19.4    82       1  \n",
            "\n",
            "[392 rows x 8 columns]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hp_mm = MS(['horsepower'])\n",
        "X_train = hp_mm.fit_transform(Auto_train)\n",
        "y_train = Auto_train['mpg']\n",
        "model = sm.OLS(y_train, X_train)\n",
        "results = model.fit()"
      ],
      "metadata": {
        "id": "6ZRMHZ5-MINl"
      },
      "id": "6ZRMHZ5-MINl",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_valid = hp_mm.transform(Auto_valid)\n",
        "y_valid = Auto_valid['mpg']\n",
        "valid_pred = results.predict(X_valid)\n",
        "np.mean((y_valid - valid_pred)**2) # MSE on validation dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTZ9uleDMK_O",
        "outputId": "b422e2df-82f8-4ca5-f841-2e069fe65966"
      },
      "id": "uTZ9uleDMK_O",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(23.015471920950535)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evalMSE(terms,\n",
        "            response,\n",
        "            train,\n",
        "            test):\n",
        "\n",
        "   mm = MS(terms)\n",
        "   X_train = mm.fit_transform(train)\n",
        "   y_train = train[response]\n",
        "\n",
        "   X_test = mm.transform(test)\n",
        "   y_test = test[response]\n",
        "\n",
        "   results = sm.OLS(y_train, X_train).fit()\n",
        "   test_pred = results.predict(X_test)\n",
        "\n",
        "   return np.mean((y_test - test_pred)**2)\n"
      ],
      "metadata": {
        "id": "tunRCqH3MSF8"
      },
      "id": "tunRCqH3MSF8",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MSE = np.zeros(3)\n",
        "for idx, degree in enumerate(range(1, 4)):\n",
        "    MSE[idx] = evalMSE([poly('horsepower', degree)],\n",
        "                       'mpg',\n",
        "                       Auto_train,\n",
        "                       Auto_valid)\n",
        "MSE\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9O_MZZhMVju",
        "outputId": "55a611d7-f14e-4045-f77a-4ca700b27a77"
      },
      "id": "m9O_MZZhMVju",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([23.01547192, 17.73173205, 17.99325931])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 5.3.2: Leave-One-Out Cross-Validation\n",
        "\n",
        "What is the leave-one-out cross-validation estimate of the test MSE for the sixth-order polynomial regression model for the Auto data set (using \"mpg\" as the response variable and \"horsepower\" as the predictor variable)? Round your answer to 2 decimal places."
      ],
      "metadata": {
        "id": "uM0cTRgpM80Y"
      },
      "id": "uM0cTRgpM80Y"
    },
    {
      "cell_type": "code",
      "source": [
        "hp_model = sklearn_sm(sm.OLS,\n",
        "                      MS(['horsepower']))\n",
        "X, Y = Auto.drop(columns=['mpg']), Auto['mpg']\n",
        "\n",
        "# help(cross_validate)\n",
        "print(Auto.shape[0])\n",
        "cv_results = cross_validate(hp_model,\n",
        "                            X,\n",
        "                            Y,\n",
        "                            cv=Auto.shape[0]  # 392 rows (Determines the cross-validation splitting strategy)\n",
        "                            )\n",
        "# print(cv_results)\n",
        "cv_err = np.mean(cv_results['test_score'])\n",
        "cv_err"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dv4p5hoWNugS",
        "outputId": "825e2d93-68d2-4a96-eb49-2fdb400a7b1a"
      },
      "id": "dv4p5hoWNugS",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "392\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(24.23151351792922)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_error = np.zeros(6)\n",
        "H = np.array(Auto['horsepower'])\n",
        "M = sklearn_sm(sm.OLS)\n",
        "\n",
        "# help(np.power.outer)\n",
        "# Loop over polynomial degrees from 1 to 6 using 'enumerate' to get both the index 'i' and degree 'd'\n",
        "for i, d in enumerate(range(1,7)):\n",
        "\n",
        "    # np.power.outer(H, np.arange(d+1)) generates [1, H, H^2, ..., H^d] for each data point\n",
        "    X = np.power.outer(H, np.arange(d+1))\n",
        "\n",
        "    # Perform cross-validation using the design matrix X and target variable Y\n",
        "    M_CV = cross_validate(M,\n",
        "                          X,\n",
        "                          Y,\n",
        "                          cv=Auto.shape[0]) # implies leave-one-out cross-validation, where each sample is used as a test set once\n",
        "\n",
        "    # Compute the mean of the cross-validation scores and store it in the cv_error array\n",
        "    cv_error[i] = np.mean(M_CV['test_score'])\n",
        "cv_error\n",
        "\n",
        "#print(X)\n",
        "#print(H)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpfEQz9fOFbB",
        "outputId": "abc0529f-2b38-494b-c73c-f8f86fbf64db"
      },
      "id": "GpfEQz9fOFbB",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([24.23151352, 19.24821312, 19.33498406, 19.42443029, 19.03320648,\n",
              "       19.00693693])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 5.3.3: k-Fold Cross-Validation\n",
        "\n",
        "Implement 5-fold cross-validation for polynomial regression models of orders one to ten for the Auto data set (using \"mpg\" as the response variable and \"horsepower\" as the predictor variable) with \"random_state=17\". What are the 5-fold cross-validation estimates of the test MSE for the linear (order one) and quadratic (order two) regression models? Round your answers to 2 decimal places."
      ],
      "metadata": {
        "id": "h0bJG14RO2kp"
      },
      "id": "h0bJG14RO2kp"
    },
    {
      "cell_type": "code",
      "source": [
        "cv_error = np.zeros(5)\n",
        "\n",
        "# help(KFold)\n",
        "\n",
        "cv = KFold(n_splits=5,\n",
        "           shuffle=True,   # Whether to shuffle the data before splitting into batches. Note that the samples within each split will not be shuffled.\n",
        "           random_state=17) # use same splits for each degree. When `shuffle` is True, `random_state` affects the ordering of the indices, which controls the randomness of each fold. Otherwise, this parameter has no effect\n",
        "\n",
        "# print(cv)\n",
        "\n",
        "for i, d in enumerate(range(1,6)):\n",
        "\n",
        "    X = np.power.outer(H, np.arange(d+1))\n",
        "\n",
        "    M_CV = cross_validate(M,\n",
        "                          X,\n",
        "                          Y,\n",
        "                          cv=cv)\n",
        "\n",
        "    cv_error[i] = np.mean(M_CV['test_score'])\n",
        "\n",
        "cv_error"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3zZLZpTO5bY",
        "outputId": "1bfc9849-e89a-48ef-cc14-5802cde6afff"
      },
      "id": "c3zZLZpTO5bY",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([24.06276551, 19.03438137, 19.01789816, 19.24324267, 18.86845234])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 5.3.4: The Bootstrap - Estimating the Accuracy of a Statistic of Interest\n",
        "\n",
        "Use \"seed=2\" to implement a bootstrap analysis of the function \"alpha_fn\" defined for the Portfolio data set. Use 1000 for the number of bootstrap estimates. What is the bootstrap estimate for the standard error of alpha-hat? Round your answer to 3 decimal places."
      ],
      "metadata": {
        "id": "R8umojbUPfXJ"
      },
      "id": "R8umojbUPfXJ"
    },
    {
      "cell_type": "code",
      "source": [
        "Portfolio = load_data('Portfolio')\n",
        "\n",
        "def alpha_func(D, idx):\n",
        "   cov_ = np.cov(D[['X','Y']].loc[idx], rowvar=False)\n",
        "   #print(cov_)\n",
        "   return ((cov_[1,1] - cov_[0,1]) /\n",
        "           (cov_[0,0]+cov_[1,1]-2*cov_[0,1]))\n",
        "\n",
        "\n",
        "def alpha_func(D, idx):\n",
        "    # Calculate the covariance matrix of columns 'X' and 'Y' from DataFrame D, using only the rows specified by the indices in idx.\n",
        "    # 'rowvar=False' ensures that each column is treated as a variable, and rows correspond to observations.\n",
        "    cov_ = np.cov(D[['X', 'Y']].loc[idx], rowvar=False)\n",
        "\n",
        "    # Return the calculated alpha value, which measures the difference between the variances of 'X' and 'Y' relative to their covariance.\n",
        "    # The formula is: (Variance of Y - Covariance between X and Y) / (Variance of X + Variance of Y - 2 * Covariance between X and Y)\n",
        "    return ((cov_[1, 1] - cov_[0, 1]) /\n",
        "            (cov_[0, 0] + cov_[1, 1] - 2 * cov_[0, 1]))"
      ],
      "metadata": {
        "id": "HGzcYntzPhwf"
      },
      "id": "HGzcYntzPhwf",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18150922",
        "outputId": "11c995ed-0d53-4114-868b-8ac7abbc6daa"
      },
      "source": [
        "# Use the existing boot_SE and alpha_func functions with the specified seed and number of bootstrap estimates\n",
        "alpha_SE_seed2 = boot_SE(alpha_func,\n",
        "                         Portfolio,\n",
        "                         B=1000,\n",
        "                         seed=2)\n",
        "\n",
        "# Print the bootstrap estimate for the standard error of alpha-hat, rounded to 3 decimal places\n",
        "print(f\"The bootstrap estimate for the standard error of alpha-hat (with seed=2) is: {alpha_SE_seed2:.3f}\")"
      ],
      "id": "18150922",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The bootstrap estimate for the standard error of alpha-hat (with seed=2) is: 0.091\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}